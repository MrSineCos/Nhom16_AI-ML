{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ad81f2",
        "outputId": "0a6bb6ce-18f5-4286-eb15-47cc46fe08e9"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.16.1)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2610401 sha256=e8592ae4af1724ec4eceeb333eb9600d8c09a9c377ccf44a0bf8c4be8d0dcc69\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96918c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4c68823f-ceb1-49c7-88e9-8c526055bfcc"
      },
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "974490df909b46a0abc95a6e09bc711e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install flask flask-ngrok\n",
        "!pip install -q pyngrok"
      ],
      "metadata": {
        "id": "gXqh6CT9KFnG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifSEPNH_wReX",
        "outputId": "efc41dfc-985b-4379-92b9-6ad58f4a1385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu...\n",
            "S·ªë l∆∞·ª£ng phim sau khi l·ªçc: 2830\n",
            "S·ªë l∆∞·ª£ng ƒë√°nh gi√°: 100004\n",
            "X·ª≠ l√Ω d·ªØ li·ªáu ho√†n t·∫•t.\n",
            "\n",
            "ƒêang x√¢y d·ª±ng m√¥ h√¨nh Content-Based (TF-IDF)...\n",
            "X√¢y d·ª±ng Content-Based ho√†n t·∫•t.\n",
            "\n",
            "ƒêang x√¢y d·ª±ng m√¥ h√¨nh Collaborative Filtering (SVD)...\n",
            "ƒêang t√≠nh to√°n tr∆∞·ªõc c√°c d·ª± ƒëo√°n SVD (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...\n",
            "X√¢y d·ª±ng SVD v√† t√≠nh to√°n tr∆∞·ªõc ho√†n t·∫•t.\n",
            "\n",
            "ƒêang x√¢y d·ª±ng b·ªô l·ªçc Popularity-Based...\n",
            "X√¢y d·ª±ng Popularity-Based ho√†n t·∫•t.\n",
            "\n",
            "==================================================\n",
            "      KH·ªûI CH·∫†Y H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T PHIM\n",
            "==================================================\n",
            "\n",
            "ƒêang t·∫£i m√¥ h√¨nh v√† m√¥i tr∆∞·ªùng d√πng chung cho API...\n",
            "ƒê√£ t·∫£i tr·ªçng s·ªë t·ª´ /content/drive/MyDrive/Colab Notebooks/Project/dqn_movie_rec_weights.weights.h5\n",
            "‚úÖ T·∫£i m√¥ h√¨nh v√† m√¥i tr∆∞·ªùng th√†nh c√¥ng.\n",
            "üöÄ B·∫Øt ƒë·∫ßu ti·∫øn tr√¨nh hu·∫•n luy·ªán online trong n·ªÅn...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Server ƒëang ch·∫°y!\n",
            " * Public URL (Ngrok): NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"\n",
            " * Local URL: http://127.0.0.1:42201\n",
            "\n",
            "C√°c endpoints c√≥ s·∫µn:\n",
            "  - ƒê·ªÅ xu·∫•t c√° nh√¢n h√≥a: NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/recommend?user_id=<ID>\n",
            "  - Phim t∆∞∆°ng t·ª±:       NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/similar_movies?movie_id=<ID>\n",
            "  - Phim ph·ªï bi·∫øn:        NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/popular_movies\n",
            "  - G·ª≠i ƒë√°nh gi√° (POST):  NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/feedback/rate\n",
            "  - G·ª≠i click (POST):     NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/feedback/click\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:42201\n",
            " * Running on http://172.28.0.12:42201\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# PH·∫¶N -1: C√ÄI ƒê·∫∂T TH∆Ø VI·ªÜN C·∫¶N THI·∫æT\n",
        "# =============================================================================\n",
        "# B·ªè comment d√≤ng d∆∞·ªõi ƒë√¢y v√† ch·∫°y n·∫øu b·∫°n ch∆∞a c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán\n",
        "# !pip install flask pandas numpy scikit-learn tensorflow surprise tqdm pyngrok\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "import socket\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Th∆∞ vi·ªán cho Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Th∆∞ vi·ªán cho API\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok, conf\n",
        "from pyngrok.exception import PyngrokError\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 0: C·∫§U H√åNH V√Ä THAM S·ªê\n",
        "# =============================================================================\n",
        "# ƒê∆∞·ªùng d·∫´n file (T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh n·∫øu kh√¥ng ·ªü trong Colab)\n",
        "if IN_COLAB:\n",
        "    DRIVE_PATH = '/content/drive/MyDrive/Colab Notebooks/Project'\n",
        "else:\n",
        "    # THAY ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N N√ÄY CHO M√ÅY T√çNH C√Å NH√ÇN C·ª¶A B·∫†N\n",
        "    DRIVE_PATH = './data' # V√≠ d·ª•: './data' ho·∫∑c 'D:/Projects/MovieRec/data'\n",
        "    if not os.path.exists(DRIVE_PATH):\n",
        "        os.makedirs(DRIVE_PATH)\n",
        "\n",
        "\n",
        "MOVIE_METADATA_PATH = os.path.join(DRIVE_PATH, 'The Movies Dataset/movies_metadata.csv')\n",
        "RATINGS_PATH = os.path.join(DRIVE_PATH, 'The Movies Dataset/ratings_small.csv')\n",
        "MODEL_WEIGHTS_PATH = os.path.join(DRIVE_PATH, 'dqn_movie_rec_weights.weights.h5')\n",
        "\n",
        "\n",
        "# Tham s·ªë m√¥ h√¨nh\n",
        "NUM_CANDIDATES = 200      # S·ªë l∆∞·ª£ng ·ª©ng vi√™n t·ª´ m√¥ h√¨nh hybrid\n",
        "TOP_N_SVD = 150           # S·ªë l∆∞·ª£ng phim l·∫•y t·ª´ SVD\n",
        "TOP_N_CONTENT = 150       # S·ªë l∆∞·ª£ng phim l·∫•y t·ª´ Content-Based\n",
        "\n",
        "# Tham s·ªë DQN\n",
        "STATE_HISTORY_LENGTH = 5  # S·ªë phim g·∫ßn nh·∫•t c√≥ rating cao ƒë·ªÉ t·∫°o state\n",
        "REWARD_THRESHOLD = 3.5    # Ng∆∞·ª°ng rating ƒë·ªÉ t√≠nh reward d∆∞∆°ng\n",
        "MAX_EPISODE_STEPS = 50    # S·ªë b∆∞·ªõc t·ªëi ƒëa trong m·ªôt episode (cho hu·∫•n luy·ªán offline)\n",
        "EPISODES = 100            # (Cho hu·∫•n luy·ªán offline)\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.95\n",
        "LEARNING_RATE = 0.001\n",
        "MEMORY_SIZE = 2000\n",
        "EPSILON_DECAY = 0.995\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 1: T·∫¢I V√Ä TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
        "# =============================================================================\n",
        "print(\"ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
        "\n",
        "try:\n",
        "    movies_df = pd.read_csv(MOVIE_METADATA_PATH, low_memory=False)\n",
        "    ratings_df = pd.read_csv(RATINGS_PATH)\n",
        "except FileNotFoundError:\n",
        "    print(\"L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.\")\n",
        "    print(f\"ƒê∆∞·ªùng d·∫´n metadata mong mu·ªën: {MOVIE_METADATA_PATH}\")\n",
        "    print(f\"ƒê∆∞·ªùng d·∫´n ratings mong mu·ªën: {RATINGS_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# --- Ti·ªÅn x·ª≠ l√Ω movies_df ---\n",
        "movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
        "movies_df.dropna(subset=['id'], inplace=True)\n",
        "movies_df['id'] = movies_df['id'].astype('int')\n",
        "movies_df['overview'] = movies_df['overview'].fillna('')\n",
        "\n",
        "# --- L·ªçc phim c√≥ trong b·ªô ratings_small ---\n",
        "movie_ids_in_ratings = ratings_df['movieId'].unique()\n",
        "small_movies_df = movies_df[movies_df['id'].isin(movie_ids_in_ratings)].copy()\n",
        "small_movies_df.drop_duplicates(subset=['id'], inplace=True)\n",
        "small_movies_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# --- S·∫Øp x·∫øp ratings theo th·ªùi gian ---\n",
        "ratings_df = ratings_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "print(f\"S·ªë l∆∞·ª£ng phim sau khi l·ªçc: {len(small_movies_df)}\")\n",
        "print(f\"S·ªë l∆∞·ª£ng ƒë√°nh gi√°: {len(ratings_df)}\")\n",
        "print(\"X·ª≠ l√Ω d·ªØ li·ªáu ho√†n t·∫•t.\")\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 2: X√ÇY D·ª∞NG C√ÅC M√î H√åNH FILTERING TRUY·ªÄN TH·ªêNG\n",
        "# =============================================================================\n",
        "\n",
        "# --- 2.1: Content-Based Filtering (D·ª±a tr√™n TF-IDF) ---\n",
        "print(\"\\nƒêang x√¢y d·ª±ng m√¥ h√¨nh Content-Based (TF-IDF)...\")\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(small_movies_df['overview'])\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "movie_id_to_idx = pd.Series(small_movies_df.index, index=small_movies_df['id'])\n",
        "print(\"X√¢y d·ª±ng Content-Based ho√†n t·∫•t.\")\n",
        "\n",
        "# --- 2.2: Collaborative Filtering (D·ª±a tr√™n SVD) ---\n",
        "print(\"\\nƒêang x√¢y d·ª±ng m√¥ h√¨nh Collaborative Filtering (SVD)...\")\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
        "trainset = data.build_full_trainset()\n",
        "svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
        "svd.fit(trainset)\n",
        "\n",
        "print(\"ƒêang t√≠nh to√°n tr∆∞·ªõc c√°c d·ª± ƒëo√°n SVD (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...\")\n",
        "anti_testset = trainset.build_anti_testset()\n",
        "svd_predictions = svd.test(anti_testset)\n",
        "from collections import defaultdict\n",
        "svd_recs_precomputed = defaultdict(list)\n",
        "for uid, iid, _, est, _ in svd_predictions:\n",
        "    svd_recs_precomputed[uid].append((iid, est))\n",
        "\n",
        "for uid, user_ratings in svd_recs_precomputed.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"X√¢y d·ª±ng SVD v√† t√≠nh to√°n tr∆∞·ªõc ho√†n t·∫•t.\")\n",
        "\n",
        "# --- 2.3: X√¢y d·ª±ng b·ªô l·ªçc Popularity-Based ---\n",
        "print(\"\\nƒêang x√¢y d·ª±ng b·ªô l·ªçc Popularity-Based...\")\n",
        "movie_rating_counts = ratings_df['movieId'].value_counts()\n",
        "popular_movies_df = small_movies_df[small_movies_df['id'].isin(movie_rating_counts.index)][['id', 'title']].copy()\n",
        "popular_movies_df['rating_count'] = popular_movies_df['id'].map(movie_rating_counts)\n",
        "popular_movies_df = popular_movies_df.sort_values('rating_count', ascending=False)\n",
        "print(\"X√¢y d·ª±ng Popularity-Based ho√†n t·∫•t.\")\n",
        "\n",
        "\n",
        "# --- 2.4: H√†m t·∫°o danh s√°ch ·ª©ng vi√™n ---\n",
        "def get_hybrid_candidates(user_id, user_history_df, num_candidates=NUM_CANDIDATES):\n",
        "    watched_movies_in_history = user_history_df['movieId'].values\n",
        "    svd_recs = [movie_id for movie_id, score in svd_recs_precomputed.get(user_id, [])\n",
        "                if movie_id not in watched_movies_in_history]\n",
        "\n",
        "    content_recs = []\n",
        "    last_liked_movie = user_history_df[user_history_df['rating'] >= REWARD_THRESHOLD].tail(1)\n",
        "\n",
        "    if not last_liked_movie.empty:\n",
        "        last_movie_id = last_liked_movie['movieId'].iloc[0]\n",
        "        if last_movie_id in movie_id_to_idx:\n",
        "            idx = movie_id_to_idx[last_movie_id]\n",
        "            sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:TOP_N_CONTENT + 1]\n",
        "            movie_indices = [i[0] for i in sim_scores]\n",
        "            content_movie_ids = small_movies_df['id'].iloc[movie_indices].tolist()\n",
        "            content_recs = [mid for mid in content_movie_ids if mid not in watched_movies_in_history]\n",
        "\n",
        "    combined_recs = svd_recs[:TOP_N_SVD] + content_recs\n",
        "    final_candidates = list(dict.fromkeys(combined_recs))\n",
        "    return final_candidates[:num_candidates]\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 3, 4, 5: M√îI TR∆Ø·ªúNG RL, T√ÅC NH√ÇN DQN V√Ä HU·∫§N LUY·ªÜN OFFLINE\n",
        "# =============================================================================\n",
        "\n",
        "class MovieRecEnv:\n",
        "    def __init__(self, ratings_data, movies_data, movie_id_map, tfidf_vectors):\n",
        "        self.ratings_df = ratings_data\n",
        "        self.movies_df = movies_data\n",
        "        self.movie_id_to_idx = movie_id_map\n",
        "        self.tfidf_matrix = tfidf_vectors\n",
        "        user_counts = self.ratings_df['userId'].value_counts()\n",
        "        self.valid_users = user_counts[user_counts >= 20].index.tolist()\n",
        "        self.state_space_size = self.tfidf_matrix.shape[1]\n",
        "        self.action_space_size = NUM_CANDIDATES\n",
        "\n",
        "    def _get_user_history(self, user_id):\n",
        "        return self.ratings_df[self.ratings_df['userId'] == user_id]\n",
        "\n",
        "    def _create_state(self, user_history_df):\n",
        "        high_rated_movies = user_history_df[user_history_df['rating'] >= REWARD_THRESHOLD].tail(STATE_HISTORY_LENGTH)\n",
        "        if high_rated_movies.empty:\n",
        "            return np.zeros(self.state_space_size)\n",
        "        movie_indices = self.movie_id_to_idx.reindex(high_rated_movies['movieId']).dropna().astype(int)\n",
        "        if movie_indices.empty:\n",
        "            return np.zeros(self.state_space_size)\n",
        "        state_vectors = self.tfidf_matrix[movie_indices]\n",
        "        return np.array(state_vectors.mean(axis=0)).flatten()\n",
        "\n",
        "    def reset(self):\n",
        "        self.candidate_movies = []\n",
        "        while len(self.candidate_movies) < self.action_space_size:\n",
        "            self.current_user_id = random.choice(self.valid_users)\n",
        "            full_user_history = self._get_user_history(self.current_user_id)\n",
        "            split_point = int(len(full_user_history) * 0.8)\n",
        "            self.rating_history = full_user_history.iloc[:split_point]\n",
        "            self.future_interact = full_user_history.iloc[split_point:]\n",
        "            if self.future_interact.empty or self.rating_history.empty:\n",
        "                continue\n",
        "            self.candidate_movies = get_hybrid_candidates(self.current_user_id, self.rating_history, self.action_space_size)\n",
        "        state = self._create_state(self.rating_history)\n",
        "        return state\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        recommended_movie_id = self.candidate_movies[action_idx]\n",
        "        actual_rating_info = self.future_interact[self.future_interact['movieId'] == recommended_movie_id]\n",
        "        reward = -0.5\n",
        "        done = False\n",
        "        if not actual_rating_info.empty:\n",
        "            actual_rating = actual_rating_info['rating'].iloc[0]\n",
        "            reward = actual_rating - REWARD_THRESHOLD\n",
        "            if reward > 0:\n",
        "                successful_record = actual_rating_info.iloc[[0]]\n",
        "                self.rating_history = pd.concat([self.rating_history, successful_record], ignore_index=True)\n",
        "        next_state = self._create_state(self.rating_history)\n",
        "        return next_state, reward, done\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
        "        self.gamma = GAMMA\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = EPSILON_DECAY\n",
        "        self.learning_rate = LEARNING_RATE\n",
        "        self.model = self._build_model()\n",
        "        self.target_model = self._build_model()\n",
        "        self.update_target_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential([\n",
        "            Input(shape=(self.state_size,)),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(self.action_size, activation='linear')\n",
        "        ])\n",
        "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state, verbose=0)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def replay(self, batch_size, memory_buffer=None):\n",
        "        # S·ª≠ d·ª•ng memory n·ªôi b·ªô n·∫øu kh√¥ng c√≥ buffer ngo√†i ƒë∆∞·ª£c cung c·∫•p\n",
        "        if memory_buffer is None:\n",
        "            memory_buffer = self.memory\n",
        "\n",
        "        if len(memory_buffer) < batch_size:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(memory_buffer, batch_size)\n",
        "        states = np.array([transition[0] for transition in minibatch]).reshape(batch_size, self.state_size)\n",
        "        next_states = np.array([transition[3] for transition in minibatch]).reshape(batch_size, self.state_size)\n",
        "\n",
        "        q_current = self.model.predict(states, verbose=0)\n",
        "        q_next = self.target_model.predict(next_states, verbose=0)\n",
        "\n",
        "        for i, (state, action, reward, next_state, done) in enumerate(minibatch):\n",
        "            target = reward if done else reward + self.gamma * np.amax(q_next[i])\n",
        "            q_current[i][action] = target\n",
        "\n",
        "        self.model.fit(states, q_current, epochs=1, verbose=0)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        if os.path.exists(name):\n",
        "            self.model.load_weights(name)\n",
        "            self.update_target_model()\n",
        "            print(f\"ƒê√£ t·∫£i tr·ªçng s·ªë t·ª´ {name}\")\n",
        "        else:\n",
        "            print(f\"Kh√¥ng t√¨m th·∫•y file tr·ªçng s·ªë {name}. B·ªè qua vi·ªác t·∫£i.\")\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)\n",
        "        print(f\"ƒê√£ l∆∞u tr·ªçng s·ªë v√†o {name}\")\n",
        "\n",
        "def train_dqn_model():\n",
        "    print(\"\\nB·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán OFFLINE...\")\n",
        "    env_offline = MovieRecEnv(ratings_df, small_movies_df, movie_id_to_idx, tfidf_matrix)\n",
        "    agent_offline = DQNAgent(env_offline.state_space_size, env_offline.action_space_size)\n",
        "\n",
        "    for e in range(EPISODES):\n",
        "        state = env_offline.reset()\n",
        "        state = np.reshape(state, [1, env_offline.state_space_size])\n",
        "        total_reward = 0\n",
        "        pbar = tqdm(range(MAX_EPISODE_STEPS), desc=f\"Episode {e+1}/{EPISODES}\")\n",
        "        for time_step in pbar:\n",
        "            action = agent_offline.act(state)\n",
        "            next_state, reward, done = env_offline.step(action)\n",
        "            total_reward += reward\n",
        "            next_state = np.reshape(next_state, [1, env_offline.state_space_size])\n",
        "            agent_offline.remember(state[0], action, reward, next_state[0], done)\n",
        "            state = next_state\n",
        "            pbar.set_postfix({\"Score\": f\"{total_reward:.2f}\", \"Epsilon\": f\"{agent_offline.epsilon:.2f}\"})\n",
        "        agent_offline.replay(BATCH_SIZE)\n",
        "        if e % 5 == 0:\n",
        "            agent_offline.update_target_model()\n",
        "    print(\"Hu·∫•n luy·ªán OFFLINE ho√†n t·∫•t.\")\n",
        "    agent_offline.save(MODEL_WEIGHTS_PATH)\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 6: C√ÅC H√ÄM ƒê·ªÄ XU·∫§T (T√°i c·∫•u tr√∫c v√† b·ªï sung)\n",
        "# =============================================================================\n",
        "\n",
        "def get_most_popular_movies(num_recs=10):\n",
        "    top_movies = popular_movies_df.head(num_recs)\n",
        "    return top_movies[['id', 'title']].to_dict('records')\n",
        "\n",
        "def get_content_based_recommendations(movie_id, num_recs=10):\n",
        "    if movie_id not in movie_id_to_idx:\n",
        "        return None\n",
        "    idx = movie_id_to_idx[movie_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:num_recs+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    recommended_movies = small_movies_df.iloc[movie_indices][['id', 'title']]\n",
        "    return recommended_movies.to_dict('records')\n",
        "\n",
        "\n",
        "def get_recommendations_for_user(user_id, agent_instance, env_instance, num_recs=10):\n",
        "    user_history = env_instance._get_user_history(user_id)\n",
        "    if user_history.empty:\n",
        "        print(f\"Kh√¥ng c√≥ d·ªØ li·ªáu cho ng∆∞·ªùi d√πng {user_id}, tr·∫£ v·ªÅ phim ph·ªï bi·∫øn.\")\n",
        "        return get_most_popular_movies(num_recs)\n",
        "\n",
        "    candidate_movies = get_hybrid_candidates(user_id, user_history, NUM_CANDIDATES)\n",
        "    if not candidate_movies:\n",
        "        print(f\"Kh√¥ng th·ªÉ t·∫°o ·ª©ng vi√™n cho ng∆∞·ªùi d√πng {user_id}, tr·∫£ v·ªÅ phim ph·ªï bi·∫øn.\")\n",
        "        return get_most_popular_movies(num_recs)\n",
        "\n",
        "    # Giai ƒëo·∫°n cold-start ho·∫∑c warm-start\n",
        "    interaction_count = len(user_history)\n",
        "    INTERACTION_THRESHOLD = 5\n",
        "    if interaction_count <= INTERACTION_THRESHOLD:\n",
        "        print(f\"User {user_id} trong giai ƒëo·∫°n COLD START. S·ª≠ d·ª•ng hybrid SVD + Content-Based.\")\n",
        "        final_recs_ids = candidate_movies[:num_recs]\n",
        "    else:\n",
        "        print(f\"User {user_id} trong giai ƒëo·∫°n WARM START. S·ª≠ d·ª•ng DQN ƒë·ªÉ x·∫øp h·∫°ng l·∫°i.\")\n",
        "        state = env_instance._create_state(user_history)\n",
        "        state = np.reshape(state, [1, env_instance.state_space_size])\n",
        "        q_values = agent_instance.model.predict(state, verbose=0)[0]\n",
        "\n",
        "        # Ch·ªâ x·∫øp h·∫°ng c√°c ·ª©ng vi√™n h·ª£p l·ªá\n",
        "        num_valid_candidates = len(candidate_movies)\n",
        "        candidate_q_values = [(candidate_movies[i], q_values[i]) for i in range(num_valid_candidates)]\n",
        "\n",
        "        sorted_recommendations = sorted(candidate_q_values, key=lambda x: x[1], reverse=True)\n",
        "        recommended_movie_ids = [movie_id for movie_id, q_value in sorted_recommendations]\n",
        "        final_recs_ids = recommended_movie_ids[:num_recs]\n",
        "\n",
        "    rec_df = small_movies_df[small_movies_df['id'].isin(final_recs_ids)][['id', 'title']]\n",
        "    # S·∫Øp x·∫øp l·∫°i dataframe theo ƒë√∫ng th·ª© t·ª± ƒë·ªÅ xu·∫•t\n",
        "    rec_df['sort_order'] = rec_df['id'].apply(lambda x: final_recs_ids.index(x))\n",
        "    rec_df = rec_df.sort_values('sort_order').drop('sort_order', axis=1)\n",
        "    return rec_df.to_dict('records')\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 7: KH·ªûI T·∫†O API V√Ä LOGIC HU·∫§N LUY·ªÜN ONLINE\n",
        "# =============================================================================\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- C√ÅC BI·∫æN TO√ÄN C·ª§C CHO API V√Ä HU·∫§N LUY·ªÜN ONLINE ---\n",
        "ONLINE_MEMORY = deque(maxlen=MEMORY_SIZE * 10) # TƒÉng k√≠ch th∆∞·ªõc cho nhi·ªÅu user\n",
        "env = None\n",
        "agent = None\n",
        "\n",
        "def background_online_training(agent_instance, memory_buffer, batch_size):\n",
        "    \"\"\"\n",
        "    H√†m n√†y ch·∫°y trong m·ªôt thread ri√™ng, li√™n t·ª•c hu·∫•n luy·ªán agent.\n",
        "    \"\"\"\n",
        "    print(\"üöÄ B·∫Øt ƒë·∫ßu ti·∫øn tr√¨nh hu·∫•n luy·ªán online trong n·ªÅn...\")\n",
        "    update_counter = 0\n",
        "    while True:\n",
        "        try:\n",
        "            if len(memory_buffer) > batch_size * 5:\n",
        "                agent_instance.replay(batch_size, memory_buffer=memory_buffer)\n",
        "                print(f\"ü§ñ ƒê√£ ch·∫°y 1 batch hu·∫•n luy·ªán online. K√≠ch th∆∞·ªõc b·ªô nh·ªõ: {len(memory_buffer)}. Epsilon: {agent_instance.epsilon:.4f}\")\n",
        "                update_counter += 1\n",
        "\n",
        "                # C·∫≠p nh·∫≠t target model sau m·ªói 100 batch\n",
        "                if update_counter % 100 == 0:\n",
        "                    agent_instance.update_target_model()\n",
        "                    print(\"üéØ ƒê√£ c·∫≠p nh·∫≠t Target Model.\")\n",
        "\n",
        "                # L∆∞u model ƒë·ªãnh k·ª≥ sau m·ªói 500 batch\n",
        "                if update_counter % 500 == 0:\n",
        "                    agent_instance.save(MODEL_WEIGHTS_PATH)\n",
        "\n",
        "            time.sleep(5) # Hu·∫•n luy·ªán m·ªói 5 gi√¢y\n",
        "        except Exception as e:\n",
        "            print(f\"L·ªói trong background training thread: {e}\")\n",
        "            time.sleep(30) # Ch·ªù l√¢u h∆°n n·∫øu c√≥ l·ªói\n",
        "\n",
        "def find_free_port():\n",
        "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    s.bind(('', 0))\n",
        "    port = s.getsockname()[1]\n",
        "    s.close()\n",
        "    return port\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 8: ƒê·ªäNH NGHƒ®A C√ÅC API ENDPOINT\n",
        "# =============================================================================\n",
        "\n",
        "@app.route('/popular_movies', methods=['GET'])\n",
        "def recommend_popular():\n",
        "    num_recs = request.args.get('num_recs', default=10, type=int)\n",
        "    return jsonify(get_most_popular_movies(num_recs))\n",
        "\n",
        "@app.route('/similar_movies', methods=['GET'])\n",
        "def recommend_similar():\n",
        "    movie_id = request.args.get('movie_id', type=int)\n",
        "    num_recs = request.args.get('num_recs', default=10, type=int)\n",
        "    if movie_id is None:\n",
        "        return jsonify({\"error\": \"Vui l√≤ng cung c·∫•p movie_id\"}), 400\n",
        "    recommendations = get_content_based_recommendations(movie_id, num_recs)\n",
        "    if recommendations is None:\n",
        "        return jsonify({\"message\": f\"Kh√¥ng t√¨m th·∫•y phim v·ªõi ID {movie_id}\"}), 404\n",
        "    return jsonify(recommendations)\n",
        "\n",
        "@app.route('/recommend', methods=['GET'])\n",
        "def recommend():\n",
        "    user_id = request.args.get('user_id', type=int)\n",
        "    num_recs = request.args.get('num_recs', default=10, type=int)\n",
        "\n",
        "    if user_id is None:\n",
        "        return jsonify({\"error\": \"Vui l√≤ng cung c·∫•p user_id\"}), 400\n",
        "    if agent is None or env is None:\n",
        "        return jsonify({\"error\": \"M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o\"}), 500\n",
        "\n",
        "    user_history = env._get_user_history(user_id)\n",
        "    state = env._create_state(user_history)\n",
        "    recommendations_dict = get_recommendations_for_user(user_id, agent, env, num_recs)\n",
        "\n",
        "    response = {\n",
        "        \"recommendations\": recommendations_dict,\n",
        "        \"context_state\": state.tolist()\n",
        "    }\n",
        "    return jsonify(response)\n",
        "\n",
        "\n",
        "@app.route('/feedback/rate', methods=['POST'])\n",
        "def receive_rating_feedback():\n",
        "    data = request.json\n",
        "    try:\n",
        "        user_id = int(data['user_id'])\n",
        "        movie_id = int(data['movie_id'])\n",
        "        rating = float(data['rating'])\n",
        "        state_at_recommendation = np.array(data['context_state'])\n",
        "    except (KeyError, TypeError, ValueError):\n",
        "        return jsonify({\"error\": \"D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá. C·∫ßn user_id, movie_id, rating, context_state\"}), 400\n",
        "\n",
        "    if agent is None or env is None:\n",
        "        return jsonify({\"error\": \"M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o\"}), 500\n",
        "\n",
        "    reward = rating - REWARD_THRESHOLD\n",
        "\n",
        "    # L∆ØU √ù QUAN TR·ªåNG:\n",
        "    # √Ånh x·∫° movie_id v·ªÅ action_index l√† m·ªôt b√†i to√°n ph·ª©c t·∫°p trong th·ª±c t·∫ø.\n",
        "    # Gi·∫£i ph√°p ƒë√∫ng ƒë·∫Øn l√† khi g·ªçi /recommend, b·∫°n c·∫ßn l∆∞u l·∫°i danh s√°ch `candidate_movies`\n",
        "    # cho user ƒë√≥ (v√≠ d·ª• trong Redis) v√† l·∫•y l·∫°i ·ªü ƒë√¢y ƒë·ªÉ t√¨m index.\n",
        "    # ƒê·ªÉ ƒë∆°n gi·∫£n h√≥a, ch√∫ng ta gi·∫£ ƒë·ªãnh action_index = 0.\n",
        "    # ƒê√ÇY L√Ä PH·∫¶N C·∫¶N C·∫¢I TI·∫æN TRONG H·ªÜ TH·ªêNG TH·ª∞C T·∫æ.\n",
        "    action_index = 0\n",
        "\n",
        "    # T·∫°o next_state\n",
        "    user_history = env._get_user_history(user_id)\n",
        "    new_rating_record = pd.DataFrame([{'userId': user_id, 'movieId': movie_id, 'rating': rating, 'timestamp': time.time()}])\n",
        "    updated_history = pd.concat([user_history, new_rating_record], ignore_index=True)\n",
        "    next_state = env._create_state(updated_history)\n",
        "\n",
        "    # ƒê·ªãnh d·∫°ng l·∫°i state ƒë·ªÉ l∆∞u v√†o b·ªô nh·ªõ\n",
        "    state = np.reshape(state_at_recommendation, [1, env.state_space_size])[0]\n",
        "    next_state_reshaped = np.reshape(next_state, [1, env.state_space_size])[0]\n",
        "\n",
        "    ONLINE_MEMORY.append((state, action_index, reward, next_state_reshaped, False))\n",
        "\n",
        "    print(f\"‚úÖ ƒê√£ nh·∫≠n feedback t·ª´ user {user_id} cho phim {movie_id}. Reward: {reward:.2f}.\")\n",
        "\n",
        "    return jsonify({\"message\": \"C·∫£m ∆°n ph·∫£n h·ªìi c·ªßa b·∫°n!\"}), 200\n",
        "\n",
        "@app.route('/feedback/click', methods=['POST'])\n",
        "def receive_click_feedback():\n",
        "    data = request.json\n",
        "    try:\n",
        "        user_id = int(data['user_id'])\n",
        "        movie_id = int(data['movie_id'])\n",
        "    except (KeyError, TypeError, ValueError):\n",
        "        return jsonify({\"error\": \"D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá. C·∫ßn user_id, movie_id\"}), 400\n",
        "\n",
        "    print(f\"üñ±Ô∏è Ghi nh·∫≠n: User {user_id} ƒë√£ ch·ªçn/click v√†o phim {movie_id}\")\n",
        "    return jsonify({\"message\": \"Ghi nh·∫≠n th√†nh c√¥ng.\"}), 200\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PH·∫¶N 9: KH·ªûI CH·∫†Y ·ª®NG D·ª§NG\n",
        "# =============================================================================\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"      KH·ªûI CH·∫†Y H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T PHIM\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # N·∫øu file weight ch∆∞a c√≥, h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën hu·∫•n luy·ªán kh√¥ng\n",
        "    if not os.path.exists(MODEL_WEIGHTS_PATH):\n",
        "        print(f\"\\nFile tr·ªçng s·ªë '{MODEL_WEIGHTS_PATH}' kh√¥ng t·ªìn t·∫°i.\")\n",
        "        choice = input(\"B·∫°n c√≥ mu·ªën hu·∫•n luy·ªán m√¥ h√¨nh (offline) kh√¥ng? (y/n): \").lower()\n",
        "        if choice == 'y':\n",
        "            train_dqn_model()\n",
        "        else:\n",
        "            print(\"B·ªè qua hu·∫•n luy·ªán. API c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông ƒë√∫ng.\")\n",
        "\n",
        "    # Kh·ªüi t·∫°o agent v√† env to√†n c·ª•c ƒë·ªÉ s·ª≠ d·ª•ng trong API\n",
        "    try:\n",
        "        print(\"\\nƒêang t·∫£i m√¥ h√¨nh v√† m√¥i tr∆∞·ªùng d√πng chung cho API...\")\n",
        "        env = MovieRecEnv(ratings_df, small_movies_df, movie_id_to_idx, tfidf_matrix)\n",
        "        agent = DQNAgent(env.state_space_size, env.action_space_size)\n",
        "        agent.load(MODEL_WEIGHTS_PATH)\n",
        "        print(\"‚úÖ T·∫£i m√¥ h√¨nh v√† m√¥i tr∆∞·ªùng th√†nh c√¥ng.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o agent/env to√†n c·ª•c: {e}\")\n",
        "        agent = None\n",
        "        env = None\n",
        "\n",
        "    if agent:\n",
        "        # T·∫°o v√† kh·ªüi ch·∫°y thread hu·∫•n luy·ªán n·ªÅn\n",
        "        training_thread = threading.Thread(\n",
        "            target=background_online_training,\n",
        "            args=(agent, ONLINE_MEMORY, BATCH_SIZE),\n",
        "            daemon=True\n",
        "        )\n",
        "        training_thread.start()\n",
        "\n",
        "    # Ch·∫°y Flask app v·ªõi ngrok\n",
        "    port = find_free_port()\n",
        "    # THAY TOKEN C·ª¶A B·∫†N V√ÄO ƒê√ÇY\n",
        "    NGROK_AUTH_TOKEN = \"31feNPxFxKOPs42wHw7YgyR8NfD_5tJA9tvGSizVzksWmF23Y\"\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\"\\nüöÄ Server ƒëang ch·∫°y!\")\n",
        "    print(f\" * Public URL (Ngrok): {public_url}\")\n",
        "    print(f\" * Local URL: http://127.0.0.1:{port}\")\n",
        "    print(\"\\nC√°c endpoints c√≥ s·∫µn:\")\n",
        "    print(f\"  - ƒê·ªÅ xu·∫•t c√° nh√¢n h√≥a: {public_url}/recommend?user_id=<ID>\")\n",
        "    print(f\"  - Phim t∆∞∆°ng t·ª±:       {public_url}/similar_movies?movie_id=<ID>\")\n",
        "    print(f\"  - Phim ph·ªï bi·∫øn:        {public_url}/popular_movies\")\n",
        "    print(f\"  - G·ª≠i ƒë√°nh gi√° (POST):  {public_url}/feedback/rate\")\n",
        "    print(f\"  - G·ª≠i click (POST):     {public_url}/feedback/click\")\n",
        "\n",
        "    try:\n",
        "        app.run(host='0.0.0.0', port=port, use_reloader=False)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n T·∫Øt ·ª©ng d·ª•ng v√† l∆∞u tr·ªçng s·ªë cu·ªëi c√πng...\")\n",
        "        if agent:\n",
        "            agent.save(MODEL_WEIGHTS_PATH)\n",
        "        ngrok.disconnect(public_url)\n",
        "        print(\"ƒê√£ l∆∞u. T·∫°m bi·ªát!\")"
      ]
    }
  ]
}