{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ad81f2",
        "outputId": "0a6bb6ce-18f5-4286-eb15-47cc46fe08e9"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.16.1)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2610401 sha256=e8592ae4af1724ec4eceeb333eb9600d8c09a9c377ccf44a0bf8c4be8d0dcc69\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96918c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4c68823f-ceb1-49c7-88e9-8c526055bfcc"
      },
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "974490df909b46a0abc95a6e09bc711e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install flask flask-ngrok\n",
        "!pip install -q pyngrok"
      ],
      "metadata": {
        "id": "gXqh6CT9KFnG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifSEPNH_wReX",
        "outputId": "efc41dfc-985b-4379-92b9-6ad58f4a1385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Đang tải và xử lý dữ liệu...\n",
            "Số lượng phim sau khi lọc: 2830\n",
            "Số lượng đánh giá: 100004\n",
            "Xử lý dữ liệu hoàn tất.\n",
            "\n",
            "Đang xây dựng mô hình Content-Based (TF-IDF)...\n",
            "Xây dựng Content-Based hoàn tất.\n",
            "\n",
            "Đang xây dựng mô hình Collaborative Filtering (SVD)...\n",
            "Đang tính toán trước các dự đoán SVD (có thể mất vài phút)...\n",
            "Xây dựng SVD và tính toán trước hoàn tất.\n",
            "\n",
            "Đang xây dựng bộ lọc Popularity-Based...\n",
            "Xây dựng Popularity-Based hoàn tất.\n",
            "\n",
            "==================================================\n",
            "      KHỞI CHẠY HỆ THỐNG ĐỀ XUẤT PHIM\n",
            "==================================================\n",
            "\n",
            "Đang tải mô hình và môi trường dùng chung cho API...\n",
            "Đã tải trọng số từ /content/drive/MyDrive/Colab Notebooks/Project/dqn_movie_rec_weights.weights.h5\n",
            "✅ Tải mô hình và môi trường thành công.\n",
            "🚀 Bắt đầu tiến trình huấn luyện online trong nền...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Server đang chạy!\n",
            " * Public URL (Ngrok): NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"\n",
            " * Local URL: http://127.0.0.1:42201\n",
            "\n",
            "Các endpoints có sẵn:\n",
            "  - Đề xuất cá nhân hóa: NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/recommend?user_id=<ID>\n",
            "  - Phim tương tự:       NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/similar_movies?movie_id=<ID>\n",
            "  - Phim phổ biến:        NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/popular_movies\n",
            "  - Gửi đánh giá (POST):  NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/feedback/rate\n",
            "  - Gửi click (POST):     NgrokTunnel: \"https://27e39be67a3f.ngrok-free.app\" -> \"http://localhost:42201\"/feedback/click\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:42201\n",
            " * Running on http://172.28.0.12:42201\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# PHẦN -1: CÀI ĐẶT THƯ VIỆN CẦN THIẾT\n",
        "# =============================================================================\n",
        "# Bỏ comment dòng dưới đây và chạy nếu bạn chưa cài đặt các thư viện\n",
        "# !pip install flask pandas numpy scikit-learn tensorflow surprise tqdm pyngrok\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "import socket\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Thư viện cho Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Thư viện cho API\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok, conf\n",
        "from pyngrok.exception import PyngrokError\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 0: CẤU HÌNH VÀ THAM SỐ\n",
        "# =============================================================================\n",
        "# Đường dẫn file (Tự động điều chỉnh nếu không ở trong Colab)\n",
        "if IN_COLAB:\n",
        "    DRIVE_PATH = '/content/drive/MyDrive/Colab Notebooks/Project'\n",
        "else:\n",
        "    # THAY ĐỔI ĐƯỜNG DẪN NÀY CHO MÁY TÍNH CÁ NHÂN CỦA BẠN\n",
        "    DRIVE_PATH = './data' # Ví dụ: './data' hoặc 'D:/Projects/MovieRec/data'\n",
        "    if not os.path.exists(DRIVE_PATH):\n",
        "        os.makedirs(DRIVE_PATH)\n",
        "\n",
        "\n",
        "MOVIE_METADATA_PATH = os.path.join(DRIVE_PATH, 'The Movies Dataset/movies_metadata.csv')\n",
        "RATINGS_PATH = os.path.join(DRIVE_PATH, 'The Movies Dataset/ratings_small.csv')\n",
        "MODEL_WEIGHTS_PATH = os.path.join(DRIVE_PATH, 'dqn_movie_rec_weights.weights.h5')\n",
        "\n",
        "\n",
        "# Tham số mô hình\n",
        "NUM_CANDIDATES = 200      # Số lượng ứng viên từ mô hình hybrid\n",
        "TOP_N_SVD = 150           # Số lượng phim lấy từ SVD\n",
        "TOP_N_CONTENT = 150       # Số lượng phim lấy từ Content-Based\n",
        "\n",
        "# Tham số DQN\n",
        "STATE_HISTORY_LENGTH = 5  # Số phim gần nhất có rating cao để tạo state\n",
        "REWARD_THRESHOLD = 3.5    # Ngưỡng rating để tính reward dương\n",
        "MAX_EPISODE_STEPS = 50    # Số bước tối đa trong một episode (cho huấn luyện offline)\n",
        "EPISODES = 100            # (Cho huấn luyện offline)\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.95\n",
        "LEARNING_RATE = 0.001\n",
        "MEMORY_SIZE = 2000\n",
        "EPSILON_DECAY = 0.995\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 1: TẢI VÀ TIỀN XỬ LÝ DỮ LIỆU\n",
        "# =============================================================================\n",
        "print(\"Đang tải và xử lý dữ liệu...\")\n",
        "\n",
        "try:\n",
        "    movies_df = pd.read_csv(MOVIE_METADATA_PATH, low_memory=False)\n",
        "    ratings_df = pd.read_csv(RATINGS_PATH)\n",
        "except FileNotFoundError:\n",
        "    print(\"Lỗi: Không tìm thấy file dữ liệu. Vui lòng kiểm tra lại đường dẫn.\")\n",
        "    print(f\"Đường dẫn metadata mong muốn: {MOVIE_METADATA_PATH}\")\n",
        "    print(f\"Đường dẫn ratings mong muốn: {RATINGS_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# --- Tiền xử lý movies_df ---\n",
        "movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
        "movies_df.dropna(subset=['id'], inplace=True)\n",
        "movies_df['id'] = movies_df['id'].astype('int')\n",
        "movies_df['overview'] = movies_df['overview'].fillna('')\n",
        "\n",
        "# --- Lọc phim có trong bộ ratings_small ---\n",
        "movie_ids_in_ratings = ratings_df['movieId'].unique()\n",
        "small_movies_df = movies_df[movies_df['id'].isin(movie_ids_in_ratings)].copy()\n",
        "small_movies_df.drop_duplicates(subset=['id'], inplace=True)\n",
        "small_movies_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# --- Sắp xếp ratings theo thời gian ---\n",
        "ratings_df = ratings_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "print(f\"Số lượng phim sau khi lọc: {len(small_movies_df)}\")\n",
        "print(f\"Số lượng đánh giá: {len(ratings_df)}\")\n",
        "print(\"Xử lý dữ liệu hoàn tất.\")\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 2: XÂY DỰNG CÁC MÔ HÌNH FILTERING TRUYỀN THỐNG\n",
        "# =============================================================================\n",
        "\n",
        "# --- 2.1: Content-Based Filtering (Dựa trên TF-IDF) ---\n",
        "print(\"\\nĐang xây dựng mô hình Content-Based (TF-IDF)...\")\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(small_movies_df['overview'])\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "movie_id_to_idx = pd.Series(small_movies_df.index, index=small_movies_df['id'])\n",
        "print(\"Xây dựng Content-Based hoàn tất.\")\n",
        "\n",
        "# --- 2.2: Collaborative Filtering (Dựa trên SVD) ---\n",
        "print(\"\\nĐang xây dựng mô hình Collaborative Filtering (SVD)...\")\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
        "trainset = data.build_full_trainset()\n",
        "svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
        "svd.fit(trainset)\n",
        "\n",
        "print(\"Đang tính toán trước các dự đoán SVD (có thể mất vài phút)...\")\n",
        "anti_testset = trainset.build_anti_testset()\n",
        "svd_predictions = svd.test(anti_testset)\n",
        "from collections import defaultdict\n",
        "svd_recs_precomputed = defaultdict(list)\n",
        "for uid, iid, _, est, _ in svd_predictions:\n",
        "    svd_recs_precomputed[uid].append((iid, est))\n",
        "\n",
        "for uid, user_ratings in svd_recs_precomputed.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"Xây dựng SVD và tính toán trước hoàn tất.\")\n",
        "\n",
        "# --- 2.3: Xây dựng bộ lọc Popularity-Based ---\n",
        "print(\"\\nĐang xây dựng bộ lọc Popularity-Based...\")\n",
        "movie_rating_counts = ratings_df['movieId'].value_counts()\n",
        "popular_movies_df = small_movies_df[small_movies_df['id'].isin(movie_rating_counts.index)][['id', 'title']].copy()\n",
        "popular_movies_df['rating_count'] = popular_movies_df['id'].map(movie_rating_counts)\n",
        "popular_movies_df = popular_movies_df.sort_values('rating_count', ascending=False)\n",
        "print(\"Xây dựng Popularity-Based hoàn tất.\")\n",
        "\n",
        "\n",
        "# --- 2.4: Hàm tạo danh sách ứng viên ---\n",
        "def get_hybrid_candidates(user_id, user_history_df, num_candidates=NUM_CANDIDATES):\n",
        "    watched_movies_in_history = user_history_df['movieId'].values\n",
        "    svd_recs = [movie_id for movie_id, score in svd_recs_precomputed.get(user_id, [])\n",
        "                if movie_id not in watched_movies_in_history]\n",
        "\n",
        "    content_recs = []\n",
        "    last_liked_movie = user_history_df[user_history_df['rating'] >= REWARD_THRESHOLD].tail(1)\n",
        "\n",
        "    if not last_liked_movie.empty:\n",
        "        last_movie_id = last_liked_movie['movieId'].iloc[0]\n",
        "        if last_movie_id in movie_id_to_idx:\n",
        "            idx = movie_id_to_idx[last_movie_id]\n",
        "            sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:TOP_N_CONTENT + 1]\n",
        "            movie_indices = [i[0] for i in sim_scores]\n",
        "            content_movie_ids = small_movies_df['id'].iloc[movie_indices].tolist()\n",
        "            content_recs = [mid for mid in content_movie_ids if mid not in watched_movies_in_history]\n",
        "\n",
        "    combined_recs = svd_recs[:TOP_N_SVD] + content_recs\n",
        "    final_candidates = list(dict.fromkeys(combined_recs))\n",
        "    return final_candidates[:num_candidates]\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 3, 4, 5: MÔI TRƯỜNG RL, TÁC NHÂN DQN VÀ HUẤN LUYỆN OFFLINE\n",
        "# =============================================================================\n",
        "\n",
        "class MovieRecEnv:\n",
        "    def __init__(self, ratings_data, movies_data, movie_id_map, tfidf_vectors):\n",
        "        self.ratings_df = ratings_data\n",
        "        self.movies_df = movies_data\n",
        "        self.movie_id_to_idx = movie_id_map\n",
        "        self.tfidf_matrix = tfidf_vectors\n",
        "        user_counts = self.ratings_df['userId'].value_counts()\n",
        "        self.valid_users = user_counts[user_counts >= 20].index.tolist()\n",
        "        self.state_space_size = self.tfidf_matrix.shape[1]\n",
        "        self.action_space_size = NUM_CANDIDATES\n",
        "\n",
        "    def _get_user_history(self, user_id):\n",
        "        return self.ratings_df[self.ratings_df['userId'] == user_id]\n",
        "\n",
        "    def _create_state(self, user_history_df):\n",
        "        high_rated_movies = user_history_df[user_history_df['rating'] >= REWARD_THRESHOLD].tail(STATE_HISTORY_LENGTH)\n",
        "        if high_rated_movies.empty:\n",
        "            return np.zeros(self.state_space_size)\n",
        "        movie_indices = self.movie_id_to_idx.reindex(high_rated_movies['movieId']).dropna().astype(int)\n",
        "        if movie_indices.empty:\n",
        "            return np.zeros(self.state_space_size)\n",
        "        state_vectors = self.tfidf_matrix[movie_indices]\n",
        "        return np.array(state_vectors.mean(axis=0)).flatten()\n",
        "\n",
        "    def reset(self):\n",
        "        self.candidate_movies = []\n",
        "        while len(self.candidate_movies) < self.action_space_size:\n",
        "            self.current_user_id = random.choice(self.valid_users)\n",
        "            full_user_history = self._get_user_history(self.current_user_id)\n",
        "            split_point = int(len(full_user_history) * 0.8)\n",
        "            self.rating_history = full_user_history.iloc[:split_point]\n",
        "            self.future_interact = full_user_history.iloc[split_point:]\n",
        "            if self.future_interact.empty or self.rating_history.empty:\n",
        "                continue\n",
        "            self.candidate_movies = get_hybrid_candidates(self.current_user_id, self.rating_history, self.action_space_size)\n",
        "        state = self._create_state(self.rating_history)\n",
        "        return state\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        recommended_movie_id = self.candidate_movies[action_idx]\n",
        "        actual_rating_info = self.future_interact[self.future_interact['movieId'] == recommended_movie_id]\n",
        "        reward = -0.5\n",
        "        done = False\n",
        "        if not actual_rating_info.empty:\n",
        "            actual_rating = actual_rating_info['rating'].iloc[0]\n",
        "            reward = actual_rating - REWARD_THRESHOLD\n",
        "            if reward > 0:\n",
        "                successful_record = actual_rating_info.iloc[[0]]\n",
        "                self.rating_history = pd.concat([self.rating_history, successful_record], ignore_index=True)\n",
        "        next_state = self._create_state(self.rating_history)\n",
        "        return next_state, reward, done\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
        "        self.gamma = GAMMA\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = EPSILON_DECAY\n",
        "        self.learning_rate = LEARNING_RATE\n",
        "        self.model = self._build_model()\n",
        "        self.target_model = self._build_model()\n",
        "        self.update_target_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential([\n",
        "            Input(shape=(self.state_size,)),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(self.action_size, activation='linear')\n",
        "        ])\n",
        "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state, verbose=0)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def replay(self, batch_size, memory_buffer=None):\n",
        "        # Sử dụng memory nội bộ nếu không có buffer ngoài được cung cấp\n",
        "        if memory_buffer is None:\n",
        "            memory_buffer = self.memory\n",
        "\n",
        "        if len(memory_buffer) < batch_size:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(memory_buffer, batch_size)\n",
        "        states = np.array([transition[0] for transition in minibatch]).reshape(batch_size, self.state_size)\n",
        "        next_states = np.array([transition[3] for transition in minibatch]).reshape(batch_size, self.state_size)\n",
        "\n",
        "        q_current = self.model.predict(states, verbose=0)\n",
        "        q_next = self.target_model.predict(next_states, verbose=0)\n",
        "\n",
        "        for i, (state, action, reward, next_state, done) in enumerate(minibatch):\n",
        "            target = reward if done else reward + self.gamma * np.amax(q_next[i])\n",
        "            q_current[i][action] = target\n",
        "\n",
        "        self.model.fit(states, q_current, epochs=1, verbose=0)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        if os.path.exists(name):\n",
        "            self.model.load_weights(name)\n",
        "            self.update_target_model()\n",
        "            print(f\"Đã tải trọng số từ {name}\")\n",
        "        else:\n",
        "            print(f\"Không tìm thấy file trọng số {name}. Bỏ qua việc tải.\")\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)\n",
        "        print(f\"Đã lưu trọng số vào {name}\")\n",
        "\n",
        "def train_dqn_model():\n",
        "    print(\"\\nBắt đầu quá trình huấn luyện OFFLINE...\")\n",
        "    env_offline = MovieRecEnv(ratings_df, small_movies_df, movie_id_to_idx, tfidf_matrix)\n",
        "    agent_offline = DQNAgent(env_offline.state_space_size, env_offline.action_space_size)\n",
        "\n",
        "    for e in range(EPISODES):\n",
        "        state = env_offline.reset()\n",
        "        state = np.reshape(state, [1, env_offline.state_space_size])\n",
        "        total_reward = 0\n",
        "        pbar = tqdm(range(MAX_EPISODE_STEPS), desc=f\"Episode {e+1}/{EPISODES}\")\n",
        "        for time_step in pbar:\n",
        "            action = agent_offline.act(state)\n",
        "            next_state, reward, done = env_offline.step(action)\n",
        "            total_reward += reward\n",
        "            next_state = np.reshape(next_state, [1, env_offline.state_space_size])\n",
        "            agent_offline.remember(state[0], action, reward, next_state[0], done)\n",
        "            state = next_state\n",
        "            pbar.set_postfix({\"Score\": f\"{total_reward:.2f}\", \"Epsilon\": f\"{agent_offline.epsilon:.2f}\"})\n",
        "        agent_offline.replay(BATCH_SIZE)\n",
        "        if e % 5 == 0:\n",
        "            agent_offline.update_target_model()\n",
        "    print(\"Huấn luyện OFFLINE hoàn tất.\")\n",
        "    agent_offline.save(MODEL_WEIGHTS_PATH)\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 6: CÁC HÀM ĐỀ XUẤT (Tái cấu trúc và bổ sung)\n",
        "# =============================================================================\n",
        "\n",
        "def get_most_popular_movies(num_recs=10):\n",
        "    top_movies = popular_movies_df.head(num_recs)\n",
        "    return top_movies[['id', 'title']].to_dict('records')\n",
        "\n",
        "def get_content_based_recommendations(movie_id, num_recs=10):\n",
        "    if movie_id not in movie_id_to_idx:\n",
        "        return None\n",
        "    idx = movie_id_to_idx[movie_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:num_recs+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    recommended_movies = small_movies_df.iloc[movie_indices][['id', 'title']]\n",
        "    return recommended_movies.to_dict('records')\n",
        "\n",
        "\n",
        "def get_recommendations_for_user(user_id, agent_instance, env_instance, num_recs=10):\n",
        "    user_history = env_instance._get_user_history(user_id)\n",
        "    if user_history.empty:\n",
        "        print(f\"Không có dữ liệu cho người dùng {user_id}, trả về phim phổ biến.\")\n",
        "        return get_most_popular_movies(num_recs)\n",
        "\n",
        "    candidate_movies = get_hybrid_candidates(user_id, user_history, NUM_CANDIDATES)\n",
        "    if not candidate_movies:\n",
        "        print(f\"Không thể tạo ứng viên cho người dùng {user_id}, trả về phim phổ biến.\")\n",
        "        return get_most_popular_movies(num_recs)\n",
        "\n",
        "    # Giai đoạn cold-start hoặc warm-start\n",
        "    interaction_count = len(user_history)\n",
        "    INTERACTION_THRESHOLD = 5\n",
        "    if interaction_count <= INTERACTION_THRESHOLD:\n",
        "        print(f\"User {user_id} trong giai đoạn COLD START. Sử dụng hybrid SVD + Content-Based.\")\n",
        "        final_recs_ids = candidate_movies[:num_recs]\n",
        "    else:\n",
        "        print(f\"User {user_id} trong giai đoạn WARM START. Sử dụng DQN để xếp hạng lại.\")\n",
        "        state = env_instance._create_state(user_history)\n",
        "        state = np.reshape(state, [1, env_instance.state_space_size])\n",
        "        q_values = agent_instance.model.predict(state, verbose=0)[0]\n",
        "\n",
        "        # Chỉ xếp hạng các ứng viên hợp lệ\n",
        "        num_valid_candidates = len(candidate_movies)\n",
        "        candidate_q_values = [(candidate_movies[i], q_values[i]) for i in range(num_valid_candidates)]\n",
        "\n",
        "        sorted_recommendations = sorted(candidate_q_values, key=lambda x: x[1], reverse=True)\n",
        "        recommended_movie_ids = [movie_id for movie_id, q_value in sorted_recommendations]\n",
        "        final_recs_ids = recommended_movie_ids[:num_recs]\n",
        "\n",
        "    rec_df = small_movies_df[small_movies_df['id'].isin(final_recs_ids)][['id', 'title']]\n",
        "    # Sắp xếp lại dataframe theo đúng thứ tự đề xuất\n",
        "    rec_df['sort_order'] = rec_df['id'].apply(lambda x: final_recs_ids.index(x))\n",
        "    rec_df = rec_df.sort_values('sort_order').drop('sort_order', axis=1)\n",
        "    return rec_df.to_dict('records')\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 7: KHỞI TẠO API VÀ LOGIC HUẤN LUYỆN ONLINE\n",
        "# =============================================================================\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- CÁC BIẾN TOÀN CỤC CHO API VÀ HUẤN LUYỆN ONLINE ---\n",
        "ONLINE_MEMORY = deque(maxlen=MEMORY_SIZE * 10) # Tăng kích thước cho nhiều user\n",
        "env = None\n",
        "agent = None\n",
        "\n",
        "def background_online_training(agent_instance, memory_buffer, batch_size):\n",
        "    \"\"\"\n",
        "    Hàm này chạy trong một thread riêng, liên tục huấn luyện agent.\n",
        "    \"\"\"\n",
        "    print(\"🚀 Bắt đầu tiến trình huấn luyện online trong nền...\")\n",
        "    update_counter = 0\n",
        "    while True:\n",
        "        try:\n",
        "            if len(memory_buffer) > batch_size * 5:\n",
        "                agent_instance.replay(batch_size, memory_buffer=memory_buffer)\n",
        "                print(f\"🤖 Đã chạy 1 batch huấn luyện online. Kích thước bộ nhớ: {len(memory_buffer)}. Epsilon: {agent_instance.epsilon:.4f}\")\n",
        "                update_counter += 1\n",
        "\n",
        "                # Cập nhật target model sau mỗi 100 batch\n",
        "                if update_counter % 100 == 0:\n",
        "                    agent_instance.update_target_model()\n",
        "                    print(\"🎯 Đã cập nhật Target Model.\")\n",
        "\n",
        "                # Lưu model định kỳ sau mỗi 500 batch\n",
        "                if update_counter % 500 == 0:\n",
        "                    agent_instance.save(MODEL_WEIGHTS_PATH)\n",
        "\n",
        "            time.sleep(5) # Huấn luyện mỗi 5 giây\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi trong background training thread: {e}\")\n",
        "            time.sleep(30) # Chờ lâu hơn nếu có lỗi\n",
        "\n",
        "def find_free_port():\n",
        "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    s.bind(('', 0))\n",
        "    port = s.getsockname()[1]\n",
        "    s.close()\n",
        "    return port\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 8: ĐỊNH NGHĨA CÁC API ENDPOINT\n",
        "# =============================================================================\n",
        "\n",
        "@app.route('/popular_movies', methods=['GET'])\n",
        "def recommend_popular():\n",
        "    num_recs = request.args.get('num_recs', default=10, type=int)\n",
        "    return jsonify(get_most_popular_movies(num_recs))\n",
        "\n",
        "@app.route('/similar_movies', methods=['GET'])\n",
        "def recommend_similar():\n",
        "    movie_id = request.args.get('movie_id', type=int)\n",
        "    num_recs = request.args.get('num_recs', default=10, type=int)\n",
        "    if movie_id is None:\n",
        "        return jsonify({\"error\": \"Vui lòng cung cấp movie_id\"}), 400\n",
        "    recommendations = get_content_based_recommendations(movie_id, num_recs)\n",
        "    if recommendations is None:\n",
        "        return jsonify({\"message\": f\"Không tìm thấy phim với ID {movie_id}\"}), 404\n",
        "    return jsonify(recommendations)\n",
        "\n",
        "@app.route('/recommend', methods=['GET'])\n",
        "def recommend():\n",
        "    user_id = request.args.get('user_id', type=int)\n",
        "    num_recs = request.args.get('num_recs', default=10, type=int)\n",
        "\n",
        "    if user_id is None:\n",
        "        return jsonify({\"error\": \"Vui lòng cung cấp user_id\"}), 400\n",
        "    if agent is None or env is None:\n",
        "        return jsonify({\"error\": \"Mô hình chưa được khởi tạo\"}), 500\n",
        "\n",
        "    user_history = env._get_user_history(user_id)\n",
        "    state = env._create_state(user_history)\n",
        "    recommendations_dict = get_recommendations_for_user(user_id, agent, env, num_recs)\n",
        "\n",
        "    response = {\n",
        "        \"recommendations\": recommendations_dict,\n",
        "        \"context_state\": state.tolist()\n",
        "    }\n",
        "    return jsonify(response)\n",
        "\n",
        "\n",
        "@app.route('/feedback/rate', methods=['POST'])\n",
        "def receive_rating_feedback():\n",
        "    data = request.json\n",
        "    try:\n",
        "        user_id = int(data['user_id'])\n",
        "        movie_id = int(data['movie_id'])\n",
        "        rating = float(data['rating'])\n",
        "        state_at_recommendation = np.array(data['context_state'])\n",
        "    except (KeyError, TypeError, ValueError):\n",
        "        return jsonify({\"error\": \"Dữ liệu không hợp lệ. Cần user_id, movie_id, rating, context_state\"}), 400\n",
        "\n",
        "    if agent is None or env is None:\n",
        "        return jsonify({\"error\": \"Mô hình chưa được khởi tạo\"}), 500\n",
        "\n",
        "    reward = rating - REWARD_THRESHOLD\n",
        "\n",
        "    # LƯU Ý QUAN TRỌNG:\n",
        "    # Ánh xạ movie_id về action_index là một bài toán phức tạp trong thực tế.\n",
        "    # Giải pháp đúng đắn là khi gọi /recommend, bạn cần lưu lại danh sách `candidate_movies`\n",
        "    # cho user đó (ví dụ trong Redis) và lấy lại ở đây để tìm index.\n",
        "    # Để đơn giản hóa, chúng ta giả định action_index = 0.\n",
        "    # ĐÂY LÀ PHẦN CẦN CẢI TIẾN TRONG HỆ THỐNG THỰC TẾ.\n",
        "    action_index = 0\n",
        "\n",
        "    # Tạo next_state\n",
        "    user_history = env._get_user_history(user_id)\n",
        "    new_rating_record = pd.DataFrame([{'userId': user_id, 'movieId': movie_id, 'rating': rating, 'timestamp': time.time()}])\n",
        "    updated_history = pd.concat([user_history, new_rating_record], ignore_index=True)\n",
        "    next_state = env._create_state(updated_history)\n",
        "\n",
        "    # Định dạng lại state để lưu vào bộ nhớ\n",
        "    state = np.reshape(state_at_recommendation, [1, env.state_space_size])[0]\n",
        "    next_state_reshaped = np.reshape(next_state, [1, env.state_space_size])[0]\n",
        "\n",
        "    ONLINE_MEMORY.append((state, action_index, reward, next_state_reshaped, False))\n",
        "\n",
        "    print(f\"✅ Đã nhận feedback từ user {user_id} cho phim {movie_id}. Reward: {reward:.2f}.\")\n",
        "\n",
        "    return jsonify({\"message\": \"Cảm ơn phản hồi của bạn!\"}), 200\n",
        "\n",
        "@app.route('/feedback/click', methods=['POST'])\n",
        "def receive_click_feedback():\n",
        "    data = request.json\n",
        "    try:\n",
        "        user_id = int(data['user_id'])\n",
        "        movie_id = int(data['movie_id'])\n",
        "    except (KeyError, TypeError, ValueError):\n",
        "        return jsonify({\"error\": \"Dữ liệu không hợp lệ. Cần user_id, movie_id\"}), 400\n",
        "\n",
        "    print(f\"🖱️ Ghi nhận: User {user_id} đã chọn/click vào phim {movie_id}\")\n",
        "    return jsonify({\"message\": \"Ghi nhận thành công.\"}), 200\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PHẦN 9: KHỞI CHẠY ỨNG DỤNG\n",
        "# =============================================================================\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"      KHỞI CHẠY HỆ THỐNG ĐỀ XUẤT PHIM\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Nếu file weight chưa có, hỏi người dùng có muốn huấn luyện không\n",
        "    if not os.path.exists(MODEL_WEIGHTS_PATH):\n",
        "        print(f\"\\nFile trọng số '{MODEL_WEIGHTS_PATH}' không tồn tại.\")\n",
        "        choice = input(\"Bạn có muốn huấn luyện mô hình (offline) không? (y/n): \").lower()\n",
        "        if choice == 'y':\n",
        "            train_dqn_model()\n",
        "        else:\n",
        "            print(\"Bỏ qua huấn luyện. API có thể không hoạt động đúng.\")\n",
        "\n",
        "    # Khởi tạo agent và env toàn cục để sử dụng trong API\n",
        "    try:\n",
        "        print(\"\\nĐang tải mô hình và môi trường dùng chung cho API...\")\n",
        "        env = MovieRecEnv(ratings_df, small_movies_df, movie_id_to_idx, tfidf_matrix)\n",
        "        agent = DQNAgent(env.state_space_size, env.action_space_size)\n",
        "        agent.load(MODEL_WEIGHTS_PATH)\n",
        "        print(\"✅ Tải mô hình và môi trường thành công.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Lỗi nghiêm trọng khi khởi tạo agent/env toàn cục: {e}\")\n",
        "        agent = None\n",
        "        env = None\n",
        "\n",
        "    if agent:\n",
        "        # Tạo và khởi chạy thread huấn luyện nền\n",
        "        training_thread = threading.Thread(\n",
        "            target=background_online_training,\n",
        "            args=(agent, ONLINE_MEMORY, BATCH_SIZE),\n",
        "            daemon=True\n",
        "        )\n",
        "        training_thread.start()\n",
        "\n",
        "    # Chạy Flask app với ngrok\n",
        "    port = find_free_port()\n",
        "    # THAY TOKEN CỦA BẠN VÀO ĐÂY\n",
        "    NGROK_AUTH_TOKEN = \"31feNPxFxKOPs42wHw7YgyR8NfD_5tJA9tvGSizVzksWmF23Y\"\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\"\\n🚀 Server đang chạy!\")\n",
        "    print(f\" * Public URL (Ngrok): {public_url}\")\n",
        "    print(f\" * Local URL: http://127.0.0.1:{port}\")\n",
        "    print(\"\\nCác endpoints có sẵn:\")\n",
        "    print(f\"  - Đề xuất cá nhân hóa: {public_url}/recommend?user_id=<ID>\")\n",
        "    print(f\"  - Phim tương tự:       {public_url}/similar_movies?movie_id=<ID>\")\n",
        "    print(f\"  - Phim phổ biến:        {public_url}/popular_movies\")\n",
        "    print(f\"  - Gửi đánh giá (POST):  {public_url}/feedback/rate\")\n",
        "    print(f\"  - Gửi click (POST):     {public_url}/feedback/click\")\n",
        "\n",
        "    try:\n",
        "        app.run(host='0.0.0.0', port=port, use_reloader=False)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n Tắt ứng dụng và lưu trọng số cuối cùng...\")\n",
        "        if agent:\n",
        "            agent.save(MODEL_WEIGHTS_PATH)\n",
        "        ngrok.disconnect(public_url)\n",
        "        print(\"Đã lưu. Tạm biệt!\")"
      ]
    }
  ]
}